{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "'''\n",
    "Класс, представляющий собой одну кинематическую пару\n",
    "'''\n",
    "class KinematicPart:\n",
    "    s = tf.constant(0, dtype=tf.float32)\n",
    "    a = tf.constant(0, dtype=tf.float32)\n",
    "    alpha = tf.constant(0, dtype=tf.float32)\n",
    "    \n",
    "    def __init__(self, s,a,alpha):\n",
    "        self.s = tf.constant(s, dtype=tf.float32)\n",
    "        self.a = tf.constant(a, dtype=tf.float32)\n",
    "        self.alpha = tf.constant(alpha, dtype=tf.float32)\n",
    "        \n",
    "    def getMatrix(self, q):\n",
    "        return [\n",
    "            [tf.cos(q), -tf.sin(q)*tf.cos(self.alpha), tf.sin(q)*tf.sin(self.alpha), self.a*tf.cos(q)],\n",
    "            [tf.sin(q), tf.cos(q)*tf.cos(self.alpha), -tf.cos(q)*tf.sin(self.alpha), self.a*tf.sin(q)],\n",
    "            [0, tf.sin(self.alpha), tf.cos(self.alpha), self.s],\n",
    "            [0, 0, 0, 1]\n",
    "                         ]\n",
    "\n",
    "\n",
    "'''\n",
    "Класс робота, состоящего из пар\n",
    "'''\n",
    "class Robot:\n",
    "    parts = []\n",
    "    \n",
    "    def __init__(self, parts):\n",
    "        self.parts = parts\n",
    "     \n",
    "    '''\n",
    "    Получить координаты схвата (конечного звена)\n",
    "    '''\n",
    "    def getXYZ(self, Q):\n",
    "        return self.getXYZPair(Q, len(self.parts))\n",
    "    \n",
    "    '''\n",
    "    Получить координаты конкретной пары \n",
    "    '''    \n",
    "    def getXYZPair(self, Q, pair):\n",
    "        \n",
    "        resultMatrix = tf.eye(4, dtype=tf.float32)\n",
    "        \n",
    "        for i,p in enumerate(self.parts):\n",
    "            \n",
    "            if i==pair:\n",
    "                break\n",
    "            \n",
    "            resultMatrix = tf.matmul(resultMatrix,p.getMatrix(Q[i]))\n",
    "        \n",
    "        xyz1 = tf.matmul(resultMatrix,tf.constant([[0],[0],[0],[1]], dtype=tf.float32))\n",
    "        #res = np.squeeze(xyz1,[3])\n",
    "        return xyz1\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Массив координат всех пар (для построения графика)\n",
    "    '''\n",
    "    def getPairPoints(self, Q):\n",
    "        \n",
    "        result = []\n",
    "        \n",
    "        for i,p in enumerate(self.parts):\n",
    "            pairXYZ = self.getXYZPair(Q,i)\n",
    "            result.append([pairXYZ[0],pairXYZ[1], pairXYZ[2]])\n",
    "        \n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r=np.pi/180.0;\n",
    "Z1 = KinematicPart(450, 320, np.pi/2)\n",
    "Z2 = KinematicPart(0, 870, 0)\n",
    "Z3 = KinematicPart(0, 1015, 0)\n",
    "Z4 = KinematicPart(0, 0, np.pi/2)\n",
    "Z5 = KinematicPart(0, 235, 0)\n",
    "\n",
    "parts = [Z1,Z2,Z3,Z4,Z5]\n",
    "\n",
    "kuka = Robot(parts)\n",
    "\n",
    "Q = tf.Variable([  0,   70*r,   230*r,\n",
    "         120*r,   0], dtype=tf.float32)\n",
    "\n",
    "xyz = kuka.getXYZ(Q)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1022.55761719]\n",
      " [ 1230.        ]\n",
      " [  370.03283691]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(model)\n",
    "    print(session.run(txyz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting at Q: [ 0.          0.34906584  0.34906584  0.34906584  0.        ] loss: 3514.07\n",
      "step 0 loss: [ 0.15811369  0.19095424  0.19141556  0.50708365 -0.15810099] loss: 2887.39\n",
      "step 50 loss: [ 0.44634253  0.00786    -0.18939403  0.64486682 -2.05218387] loss: 989.65\n",
      "step 100 loss: [ 0.64476562  0.19616881 -0.81027079  0.20415816 -3.06229806] loss: 701.285\n",
      "step 150 loss: [ 0.80672216  0.57842249 -1.64448833  0.36607713 -3.08528376] loss: 73.9481\n",
      "step 200 loss: [ 0.82425773  0.62020767 -1.6915679   0.33558872 -3.06608462] loss: 6.93327\n",
      "step 250 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 300 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 350 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 400 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 450 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 500 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 550 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 600 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 650 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 700 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 750 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 800 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 850 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 900 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 950 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 1000 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 1050 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 1100 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 1150 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 1200 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 1250 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 1300 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 1350 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 1400 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 1450 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 1500 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 1550 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 1600 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 1650 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 1700 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 1750 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 1800 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 1850 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 1900 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 1950 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 2000 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 2050 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 2100 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 2150 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 2200 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 2250 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 2300 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 2350 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 2400 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 2450 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 2500 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 2550 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 2600 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 2650 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 2700 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 2750 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 2800 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 2850 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 2900 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 2950 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 3000 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 3050 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 3100 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 3150 loss: [ 0.82660878  0.61751044 -1.69165885  0.31441164 -3.08559656] loss: 4.26808\n",
      "step 3200 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 3250 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 3300 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 3350 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 3400 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 3450 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 3500 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 3550 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 3600 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 3650 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 3700 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 3750 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 3800 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 3850 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 3900 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 3950 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 4000 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 4050 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 4100 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 4150 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 4200 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 4250 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 4300 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 4350 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 4400 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 4450 loss: [ 0.85768628  0.60182315 -1.80918074 -0.14163235 -3.24985456] loss: 2.2135\n",
      "step 4500 loss: [ 0.85600084  0.60595781 -1.82438529 -0.17618415 -3.24374032] loss: 2.06779\n",
      "step 4550 loss: [ 0.85600084  0.60595781 -1.82438529 -0.17618415 -3.24374032] loss: 2.06779\n",
      "step 4600 loss: [ 0.85600084  0.60595781 -1.82438529 -0.17618415 -3.24374032] loss: 2.06779\n",
      "step 4650 loss: [ 0.85600084  0.60595781 -1.82438529 -0.17618415 -3.24374032] loss: 2.06779\n",
      "step 4700 loss: [ 0.85600084  0.60595781 -1.82438529 -0.17618415 -3.24374032] loss: 2.06779\n",
      "step 4750 loss: [ 0.85600084  0.60595781 -1.82438529 -0.17618415 -3.24374032] loss: 2.06779\n",
      "step 4800 loss: [ 0.85600084  0.60595781 -1.82438529 -0.17618415 -3.24374032] loss: 2.06779\n",
      "step 4850 loss: [ 0.85600084  0.60595781 -1.82438529 -0.17618415 -3.24374032] loss: 2.06779\n",
      "step 4900 loss: [ 0.85600084  0.60595781 -1.82438529 -0.17618415 -3.24374032] loss: 2.06779\n",
      "step 4950 loss: [ 0.85600084  0.60595781 -1.82438529 -0.17618415 -3.24374032] loss: 2.06779\n",
      "bestQ:  [ 0.85600084  0.60595781 -1.82438529 -0.17618415 -3.24374032]  bestLoss:  2.06779\n"
     ]
    }
   ],
   "source": [
    "Q0 = tf.Variable([  0,   20*r,   20*r,\n",
    "         20*r,   0],dtype=tf.float32)\n",
    "\n",
    "target = tf.constant([[900],[1000],[222]], dtype=tf.float32)\n",
    "\n",
    "xyz = kuka.getXYZ(Q0)[:3]\n",
    "\n",
    "loss = tf.reduce_sum(tf.sqrt(tf.pow(target-xyz, 2)))\n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(0.05)\n",
    "\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "model = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(model)\n",
    "    bestQ = session.run(Q0)\n",
    "    bestLoss = session.run(loss)\n",
    "    print(\"starting at\", \"Q:\", bestQ, \"loss:\", bestLoss)\n",
    "    for step in range(5000):  \n",
    "        session.run(train)\n",
    "        \n",
    "        curQ = session.run(Q0)\n",
    "        curLoss = session.run(loss)\n",
    "        \n",
    "        if curLoss < bestLoss:\n",
    "            bestLoss = curLoss\n",
    "            bestQ = curQ\n",
    "        \n",
    "        if(step % 50 == 0):\n",
    "            print(\"step\", step, \"loss:\", bestQ, \"loss:\", bestLoss)\n",
    "    \n",
    "    print(\"bestQ: \", bestQ, \" bestLoss: \", bestLoss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
